# Sample configuration file
# Modify then run "spider --config=/path/to/config.ini"
# Uses INI-style syntax, see https://docs.python.org/3/library/configparser.html

[COLLECTORS]
# List of Collectors that should be queried for the location of Schedds.
# Each Collector address must be on its own line.
cm.chtc.wisc.edu

[SCHEDDS]
# List of Schedds that should be queried.
# Each Schedd name should be on its own line.
# If no Schedds are defined here, all Schedds located by the Collectors will
# be queried.
submit-1.chtc.wisc.edu
submit-2.chtc.wisc.edu
submit-3.chtc.wisc.edu

[PROCESS]
schedd_history = True
schedd_queue = False

# Process at most $(max_documents) per Schedd, 0 [default] = process all documents.
max_documents = 0

# Use multithreading to query $(parallel_queries) Schedds at the same time.
#parallel_queries = 8

[ELASTICSEARCH]
# https requires that certifi be installed
use_https = False
host = tiger-es.chtc.wisc.edu
port = 9200
username = esuser
password = changeme
bunch_size = 250

feed_schedd_history = True
feed_schedd_queue = False

# Documents are placed in indexes named $(index_name)-YYYY-MM-DD (shard per day)
# with the date generated from $(index_date_attr) ("CompletionDate" by default)
index_name = htcondor_jobs
index_date_attr = CompletionDate
